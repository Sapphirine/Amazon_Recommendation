{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/Users/lmh/Programs/spark-2.2.0-bin-hadoop2.7')\n",
    "from pyspark.sql import SparkSession \n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from matplotlib import pyplot as plt\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'3603', u'5.0', u'2838'],\n",
       " [u'3603', u'4.0', u'7527'],\n",
       " [u'523', u'1.0', u'6801'],\n",
       " [u'2055', u'5.0', u'254'],\n",
       " [u'1350', u'5.0', u'3979'],\n",
       " [u'1417', u'5.0', u'6297'],\n",
       " [u'1417', u'5.0', u'3264'],\n",
       " [u'2906', u'5.0', u'4006'],\n",
       " [u'2906', u'5.0', u'2403'],\n",
       " [u'2906', u'5.0', u'1888']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.textFile('./csv/Pre_100k.csv')\n",
    "rdd = rdd.map(lambda x: x.split(','))\n",
    "rdd.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrdd = rdd.map(lambda x: Row(userid = int(x[2]),\n",
    "                              rating = float(x[1]),\n",
    "                              itemid = int(x[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+\n",
      "|itemid|rating|userid|\n",
      "+------+------+------+\n",
      "|  3603|   5.0|  2838|\n",
      "|  3603|   4.0|  7527|\n",
      "|   523|   1.0|  6801|\n",
      "|  2055|   5.0|   254|\n",
      "|  1350|   5.0|  3979|\n",
      "|  1417|   5.0|  6297|\n",
      "|  1417|   5.0|  3264|\n",
      "|  2906|   5.0|  4006|\n",
      "|  2906|   5.0|  2403|\n",
      "|  2906|   5.0|  1888|\n",
      "|  2906|   5.0|  1485|\n",
      "|  2906|   5.0|  4489|\n",
      "|  2906|   4.0|  2984|\n",
      "|  2906|   5.0|   137|\n",
      "|  2906|   5.0|  2963|\n",
      "|  2906|   5.0|   912|\n",
      "|   589|   5.0|   644|\n",
      "|   589|   5.0|   583|\n",
      "|   589|   5.0|  3233|\n",
      "|   589|   5.0|    14|\n",
      "+------+------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(dfrdd)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+------+------+\n",
      "|mean|itemid|rating|userid|\n",
      "+----+------+------+------+\n",
      "| 5.0|   701|   5.0|    26|\n",
      "| 4.0|  2332|   4.0|    29|\n",
      "| 5.0|  1681|   5.0|   474|\n",
      "| 5.0|  3432|   5.0|   964|\n",
      "| 5.0|  2161|   5.0|  1677|\n",
      "| 5.0|  1806|   5.0|  1697|\n",
      "| 1.0|  2142|   1.0|  1806|\n",
      "| 5.0|  1233|   5.0|  1950|\n",
      "| 5.0|   258|   5.0|  2040|\n",
      "| 5.0|  1118|   5.0|  2214|\n",
      "| 5.0|   631|   5.0|  2250|\n",
      "| 1.0|  1024|   1.0|  2453|\n",
      "| 4.0|  1515|   4.0|  2509|\n",
      "| 5.0|  2401|   5.0|  2529|\n",
      "| 5.0|  3703|   5.0|  2927|\n",
      "| 5.0|  3070|   5.0|  3091|\n",
      "| 5.0|    68|   5.0|  3091|\n",
      "| 5.0|  2930|   5.0|  3091|\n",
      "| 4.0|   704|   4.0|  3506|\n",
      "| 5.0|   595|   5.0|  3764|\n",
      "+----+------+------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tdf = df.groupby('userid').agg({'rating': 'mean'})\n",
    "df = tdf.join(df, tdf.userid == df.userid).drop(tdf.userid)\n",
    "df = df.withColumnRenamed('avg(rating)', 'mean')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
