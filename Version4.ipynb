{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/Users/lmh/Programs/spark-2.2.0-bin-hadoop2.7')\n",
    "from pyspark.sql import SparkSession \n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from matplotlib import pyplot as plt\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'3603', u'5.0', u'2838'],\n",
       " [u'3603', u'4.0', u'7527'],\n",
       " [u'523', u'1.0', u'6801'],\n",
       " [u'2055', u'5.0', u'254'],\n",
       " [u'1350', u'5.0', u'3979'],\n",
       " [u'1417', u'5.0', u'6297'],\n",
       " [u'1417', u'5.0', u'3264'],\n",
       " [u'2906', u'5.0', u'4006'],\n",
       " [u'2906', u'5.0', u'2403'],\n",
       " [u'2906', u'5.0', u'1888']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.textFile('./csv/Pre_100k.csv')\n",
    "rdd = rdd.map(lambda x: x.split(','))\n",
    "rdd.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrdd = rdd.map(lambda x: Row(userid = int(x[2]),\n",
    "                              rating = float(x[1]),\n",
    "                              itemid = int(x[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+\n",
      "|itemid|rating|userid|\n",
      "+------+------+------+\n",
      "|  3603|   5.0|  2838|\n",
      "|  3603|   4.0|  7527|\n",
      "|   523|   1.0|  6801|\n",
      "|  2055|   5.0|   254|\n",
      "|  1350|   5.0|  3979|\n",
      "|  1417|   5.0|  6297|\n",
      "|  1417|   5.0|  3264|\n",
      "|  2906|   5.0|  4006|\n",
      "|  2906|   5.0|  2403|\n",
      "|  2906|   5.0|  1888|\n",
      "|  2906|   5.0|  1485|\n",
      "|  2906|   5.0|  4489|\n",
      "|  2906|   4.0|  2984|\n",
      "|  2906|   5.0|   137|\n",
      "|  2906|   5.0|  2963|\n",
      "|  2906|   5.0|   912|\n",
      "|   589|   5.0|   644|\n",
      "|   589|   5.0|   583|\n",
      "|   589|   5.0|  3233|\n",
      "|   589|   5.0|    14|\n",
      "+------+------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(dfrdd)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = df.randomSplit([0.9, 0.1], 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = splits[0]\n",
    "testdf = splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ALS(maxIter = 5, regParam = 0.01, implicitPrefs = False, \n",
    "          userCol = \"userid\", itemCol=\"itemid\", ratingCol=\"rating\",\n",
    "          coldStartStrategy=\"drop\")\n",
    "model = als.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+----------+\n",
      "|itemid|rating|userid|prediction|\n",
      "+------+------+------+----------+\n",
      "|   463|   5.0|  3093|  4.999531|\n",
      "|  1959|   5.0|  7290|  4.997807|\n",
      "|  1143|   5.0|  4927|  4.998475|\n",
      "|  3000|   4.0|  2374| 3.9972644|\n",
      "|    65|   5.0|  3383|  4.997807|\n",
      "|  1977|   3.0|  4773| 2.9996648|\n",
      "|  2249|   5.0|  4934| 4.9987793|\n",
      "|  2833|   5.0|   353|  4.997807|\n",
      "|   799|   5.0|  3981| 4.9994607|\n",
      "|  2156|   5.0|  1284| 4.9987197|\n",
      "|   296|   5.0|  1394|  4.997807|\n",
      "|  1466|   5.0|  6205|  4.997807|\n",
      "|  1766|   5.0|  6152|  4.999999|\n",
      "|  1766|   4.0|  7420| 3.9996452|\n",
      "|  2874|   4.0|  4515|  3.997264|\n",
      "|   322|   5.0|   605|  4.997807|\n",
      "|   513|   5.0|  6599|  4.997807|\n",
      "|   918|   5.0|   323|  4.999449|\n",
      "|   918|   5.0|   681|  4.999449|\n",
      "|  3657|   5.0|  7656|  4.999352|\n",
      "+------+------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = model.transform(testdf)\n",
    "pred.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 4.61857167733\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(pred)\n",
    "print(\"Root-mean-square error = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
